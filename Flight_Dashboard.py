# Flight_Dashboard.py
# Streamlit Flight Dashboard (tabs + filters + calendar view + maintenance)
# -----------------------------------------------------------
# Run:
#   streamlit run Flight_Dashboard.py

import os
import io
import re
import math
import numpy as np
import pandas as pd
import streamlit as st
from datetime import datetime, date, timedelta
import calendar
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go

# ====== USER DEFAULTS ======
# DEFAULT_FILE_PATH = "RBG Flight Dashboard/Flight_Summary_1.xlsx"
#
# BATTERY_CSV_PATH = "RBG Flight Dashboard/UAV_BATTERY_LOGS.csv"
#
# # Battery files
# DEFAULT_BATT_CYCLES_PATH = "RBG Flight Dashboard/battery_cycles_long.csv"
# DEFAULT_BATT_VOLT_PATH = "RBG Flight Dashboard/battery_voltage_stats.csv"

from pathlib import Path
# import streamlit as st

try:
    BASE_DIR = Path(__file__).resolve().parent
except NameError:
    BASE_DIR = Path.cwd()

DEFAULT_FILE_PATH = BASE_DIR / "Flight_Summary_1.xlsx"
BATTERY_CSV_PATH = BASE_DIR / "UAV_BATTERY_LOGS.csv"
DEFAULT_BATT_CYCLES_PATH = BASE_DIR / "battery_cycles_long.csv"
DEFAULT_BATT_VOLT_PATH = BASE_DIR / "battery_voltage_stats.csv"


# Thresholds
CYCLE_DECOMMISSION_LIMIT = 200
CELL_DELTA_WARN_V = 0.001
MAINTENANCE_HOURS_LIMIT = 200


# ----------------------- Robust Loader -----------------------
@st.cache_data(show_spinner=False)
def load_dataframe(file_or_buffer):
    """
    Robust reader:
    - Detects extension (for paths and uploaded files)
    - Uses proper Excel engines
    - Tries multiple CSV encodings if needed
    """

    def _read_excel(src, ext):
        if ext in (".xlsx", ".xlsm", ".xltx", ".xltm"):
            return pd.read_excel(src, engine="openpyxl")
        elif ext == ".xls":
            try:
                return pd.read_excel(src, engine="xlrd")
            except Exception as e:
                raise RuntimeError("Reading legacy .xls requires 'xlrd' (pip install xlrd).") from e
        else:
            return pd.read_excel(src)

    def _read_csv_with_fallbacks(src):
        for enc in ("utf-8", "utf-8-sig", "latin-1"):
            try:
                return pd.read_csv(src, encoding=enc)
            except UnicodeDecodeError:
                continue
        return pd.read_csv(src, encoding="utf-8", errors="replace")

    if isinstance(file_or_buffer, str):
        path = file_or_buffer
        if not os.path.exists(path):
            raise FileNotFoundError(f"File not found: {path}")

        ext = os.path.splitext(path)[1].lower()
        if ext in (".xlsx", ".xlsm", ".xltx", ".xltm", ".xls"):
            try:
                return _read_excel(path, ext)
            except ImportError as e:
                raise RuntimeError(
                    "Excel engine missing. Install:\n"
                    "  pip install openpyxl  (for .xlsx/.xlsm)\n"
                    "  pip install xlrd      (for legacy .xls)"
                ) from e
        elif ext in (".csv", ".txt"):
            return _read_csv_with_fallbacks(path)
        else:
            try:
                return _read_excel(path, ".xlsx")
            except Exception:
                return _read_csv_with_fallbacks(path)

    name = getattr(file_or_buffer, "name", "uploaded")
    ext = os.path.splitext(name)[1].lower()
    buffer = file_or_buffer

    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm", ".xls"):
        try:
            return _read_excel(buffer, ext)
        except ImportError as e:
            raise RuntimeError(
                "Excel engine missing. Install:\n"
                "  pip install openpyxl  (for .xlsx/.xlsm)\n"
                "  pip install xlrd      (for legacy .xls)"
            ) from e
    elif ext in (".csv", ".txt"):
        return _read_csv_with_fallbacks(buffer)
    else:
        try:
            return _read_excel(buffer, ".xlsx")
        except Exception:
            if hasattr(buffer, "seek"):
                buffer.seek(0)
            return _read_csv_with_fallbacks(buffer)


# ----------------------- Helpers & Parsing -----------------------
def guess_datetime_columns(df: pd.DataFrame):
    candidates = []
    for c in df.columns:
        lc = c.lower()
        if any(k in lc for k in ["date", "time", "start", "timestamp", "log", "flight_date"]):
            candidates.append(c)
    scored = []
    for c in candidates:
        try:
            parsed = pd.to_datetime(df[c], errors="coerce")
            score = parsed.notna().sum()
            if score > 0:
                scored.append((c, score))
        except Exception:
            pass
    scored.sort(key=lambda x: x[1], reverse=True)
    return [c for c, _ in scored]


def guess_duration_columns(df: pd.DataFrame):
    candidates = []
    for c in df.columns:
        lc = c.lower()
        if any(k in lc for k in ["duration", "flight_time", "time_mins", "time_min", "mins", "minutes", "elapsed"]):
            candidates.append(c)
    for c in df.columns:
        if df[c].dtype == object:
            sample = df[c].astype(str).head(30).tolist()
            if any(re.match(r"^\s*\d{1,2}:\d{2}(:\d{2})?\s*$", s) for s in sample):
                candidates.append(c)
    return list(dict.fromkeys(candidates))


def to_datetime_series(s):
    return pd.to_datetime(s, errors="coerce")


def parse_duration_to_minutes(series: pd.Series) -> pd.Series:
    name_hint = (series.name or "").lower()
    if pd.api.types.is_numeric_dtype(series):
        vals = series.astype(float)
        if "sec" in name_hint or "second" in name_hint:
            return vals / 60.0
        return vals.astype(float)

    def parse_one(x):
        if pd.isna(x):
            return np.nan
        s = str(x).strip()
        m = re.match(r"^(\d{1,2}):(\d{2})(?::(\d{2}))?$", s)
        if m:
            hh = int(m.group(1));
            mm = int(m.group(2));
            ss = int(m.group(3)) if m.group(3) else 0
            return hh * 60 + mm + ss / 60.0
        try:
            val = float(s.replace(",", ""))
            if "sec" in name_hint or "second" in name_hint:
                return val / 60.0
            return val
        except Exception:
            return np.nan

    return series.map(parse_one)


def minutes_to_hms_str(total_minutes: float):
    if pd.isna(total_minutes):
        return "0h 00m"
    total_seconds = int(round(total_minutes * 60))
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    return f"{hours}h {minutes:02d}m"


def month_calendar_dataframe(year: int, month: int, flights_by_day: dict):
    cal = calendar.Calendar(firstweekday=0)
    month_days = cal.monthdayscalendar(year, month)
    while len(month_days) < 6:
        month_days.append([0] * 7)
    matrix = []
    for week in month_days:
        row = []
        for d in week:
            cnt = flights_by_day.get(d, 0) if d != 0 else 0
            row.append((d, cnt))
        matrix.append(row)
    return matrix


# ----------------- Battery helpers -----------------
def _guess_batt_id_cols(df: pd.DataFrame):
    hits = [c for c in df.columns if
            any(k in c.lower() for k in ["battery", "batt", "pack", "sn", "serial", "id", "index"])]
    return list(dict.fromkeys(hits)) or list(df.columns)


def _guess_cycle_cols(df: pd.DataFrame):
    hits = [c for c in df.columns if any(k in c.lower() for k in ["cycle", "charge_count", "charges", "count"])]
    return hits or list(df.columns)


def _guess_datetime_cols(df: pd.DataFrame):
    return guess_datetime_columns(df) or list(df.columns)


def _detect_cell_voltage_cols(df: pd.DataFrame):
    patt = re.compile(r"(cell\s*\d+.*v|^v\d+|cell\d+|cell_?\d+|cell.*voltage)", re.IGNORECASE)
    cand = []
    for c in df.columns:
        if pd.api.types.is_numeric_dtype(df[c]) and patt.search(c):
            cand.append(c)
    common = [c for c in df.columns if
              c.strip().lower() in {"cell1v", "cell2v", "cell3v", "cell4v", "cell5v", "cell6v"}]
    return list(dict.fromkeys(cand + common))


def prepare_batt_voltage_stats(df_raw: pd.DataFrame) -> pd.DataFrame:
    if df_raw is None or df_raw.empty:
        return pd.DataFrame()

    df = df_raw.copy()

    batt_col_candidates = _guess_batt_id_cols(df)
    battery_col = batt_col_candidates[0] if batt_col_candidates else None
    if battery_col is None:
        df["battery_index"] = "battery_1"
    else:
        df["battery_index"] = df[battery_col].astype(str)

    dt_candidates = _guess_datetime_cols(df)
    date_col = dt_candidates[0] if dt_candidates else None
    if date_col is not None:
        df["Date"] = to_datetime_series(df[date_col])
    else:
        df["Date"] = pd.NaT

    lower_cols = {c.lower(): c for c in df.columns}
    min_col = lower_cols.get("min_volt")
    max_col = lower_cols.get("max_volt")

    if (min_col is None) or (max_col is None):
        cell_cols = _detect_cell_voltage_cols(df)
        cell_cols = [c for c in cell_cols if pd.api.types.is_numeric_dtype(df[c])]
        if len(cell_cols) >= 2:
            df["min_volt"] = df[cell_cols].min(axis=1)
            df["max_volt"] = df[cell_cols].max(axis=1)
        else:
            guess_min = [c for c in df.columns if "min" in c.lower() and "v" in c.lower()]
            guess_max = [c for c in df.columns if "max" in c.lower() and "v" in c.lower()]
            if guess_min and guess_max:
                df["min_volt"] = pd.to_numeric(df[guess_min[0]], errors="coerce")
                df["max_volt"] = pd.to_numeric(df[guess_max[0]], errors="coerce")
            else:
                return pd.DataFrame()
    else:
        df["min_volt"] = pd.to_numeric(df[min_col], errors="coerce")
        df["max_volt"] = pd.to_numeric(df[max_col], errors="coerce")

    if "delta" not in df.columns:
        df["delta"] = df["max_volt"] - df["min_volt"]
    else:
        df["delta"] = pd.to_numeric(df["delta"], errors="coerce")
        df["delta"] = df["delta"].fillna(df["max_volt"] - df["min_volt"])

    out = df[["Date", "battery_index", "min_volt", "max_volt", "delta"]].copy()
    out = out.dropna(subset=["Date"])
    return out.sort_values("Date")


def prepare_batt_cycles(df_raw: pd.DataFrame) -> pd.DataFrame:
    if df_raw is None or df_raw.empty:
        return pd.DataFrame()

    df = df_raw.copy()

    batt_col_candidates = _guess_batt_id_cols(df)
    battery_col = batt_col_candidates[0] if batt_col_candidates else None
    if battery_col is None:
        df["battery_index"] = "battery_1"
    else:
        df["battery_index"] = df[battery_col].astype(str)

    cyc_candidates = _guess_cycle_cols(df)
    cycles_col = cyc_candidates[0] if cyc_candidates else None
    if cycles_col is None:
        return pd.DataFrame()

    df["cycles"] = pd.to_numeric(df[cycles_col], errors="coerce")

    dt_candidates = _guess_datetime_cols(df)
    if dt_candidates:
        df["Date"] = to_datetime_series(df[dt_candidates[0]])
    else:
        df["Date"] = pd.NaT

    out = df[["Date", "battery_index", "cycles"]].copy()
    return out


# ----------------------- UI -----------------------
st.set_page_config(page_title="Flight Dashboard", layout="wide", initial_sidebar_state="expanded")
st.title("üõ∞Ô∏è Flight Dashboard")

# File input
with st.sidebar:
    st.header("Data")
    file_choice = st.radio("Choose data source", ["Use default path", "Upload file"], horizontal=True)
    data = None
    if file_choice == "Use default path":
        st.caption(f"Default: `{DEFAULT_FILE_PATH}`")
        try:
            data = load_dataframe(DEFAULT_FILE_PATH)
            st.success(f"Loaded {len(data):,} rows from default path.")
        except FileNotFoundError as e:
            st.warning(str(e))
            data = None
        except Exception as e:
            st.error(f"Failed to load default path: {e}")
            data = None
    else:
        up = st.file_uploader("Upload Excel/CSV", type=["xlsx", "xls", "xlsm", "csv", "txt"])
        if up is not None:
            try:
                data = load_dataframe(up)
                st.success(f"Loaded {len(data):,} rows from uploaded file.")
            except Exception as e:
                st.error(f"Failed to read uploaded file: {e}")
                data = None

    # Column mapping
    if data is not None:
        st.subheader("Column Mapping")
        dt_candidates = guess_datetime_columns(data)
        dur_candidates = guess_duration_columns(data)

        dt_col = st.selectbox(
            "Date/Datetime column",
            options=[None] + dt_candidates + list(data.columns),
            index=1 if dt_candidates else 0
        )
        dur_col = st.selectbox(
            "Duration column (mins or HH:MM:SS)",
            options=[None] + dur_candidates + list(data.columns),
            index=1 if dur_candidates else 0
        )
    else:
        dt_col = None
        dur_col = None

if data is None:
    st.stop()

# Prepare dataframe
df = data.copy()

# Parse datetime
if dt_col is None:
    st.error("Please select a Date/Datetime column in the sidebar.")
    st.stop()

df["__dt__"] = to_datetime_series(df[dt_col])
df = df[df["__dt__"].notna()].copy()
if df.empty:
    st.error("No valid datetime values after parsing the selected column.")
    st.stop()

df["__date__"] = df["__dt__"].dt.date
df["__year__"] = df["__dt__"].dt.year
df["__month__"] = df["__dt__"].dt.month
df["__day__"] = df["__dt__"].dt.day

# Parse duration -> minutes
if dur_col is None:
    st.warning("No duration column selected. Duration metrics will be 0.")
    df["__mins__"] = 0.0
else:
    df["__mins__"] = parse_duration_to_minutes(df[dur_col].copy()).fillna(0.0)

df["__hours__"] = df["__mins__"] / 60.0

# ================= Tabs =================
tab1, tab2, tab3, tab4 = st.tabs(["üìä General Statistics", "‚è±Ô∏è Flight Duration", "üîã Battery Health", "üîß Maintenance"])

# ----------------------- TAB 1: GENERAL -----------------------
with tab1:
    st.subheader("Overview")
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        st.metric("Total Flights", f"{len(df):,}")
    with c2:
        total_mins = df["__mins__"].sum()
        st.metric("Total Duration (hours)", f"{total_mins / 60.0:,.2f}")
    with c3:
        avg_min = df["__mins__"].replace(0, np.nan).mean()
        st.metric("Avg Flight (mins)", f"{avg_min:,.1f}" if not np.isnan(avg_min) else "0.0")
    with c4:
        unique_days = df["__date__"].nunique()
        st.metric("Active Flight Days", f"{unique_days:,}")

    st.markdown("---")
    st.subheader("Flights per Year / Month")
    by_year = df.groupby("__year__").size().rename("flights").reset_index()
    by_month = df.groupby(["__year__", "__month__"]).size().rename("flights").reset_index()

    c5, c6 = st.columns(2)
    with c5:
        st.markdown("**Flights per Year**")
        if not by_year.empty:
            st.bar_chart(by_year.set_index("__year__")["flights"])
        else:
            st.info("No yearly data available.")

    with c6:
        st.markdown("**Flights per Month (stacked by year)**")
        if not by_month.empty:
            piv = by_month.pivot(index="__month__", columns="__year__", values="flights").fillna(0).sort_index()
            st.bar_chart(piv)
        else:
            st.info("No monthly data available.")

    st.markdown("---")
    st.subheader("Duration per Year (hours)")
    dur_year = df.groupby("__year__")["__hours__"].sum().rename("hours").reset_index()
    if not dur_year.empty:
        st.bar_chart(dur_year.set_index("__year__")["hours"])
    else:
        st.info("No duration data available.")

# ----------------------- TAB 2: DURATION + FILTERS + CALENDAR -----------------------
with tab2:
    st.subheader("Filters")

    years = sorted(df["__year__"].unique().tolist())
    months = list(range(1, 13))
    days_all = list(range(1, 32))

    colf1, colf2, colf3 = st.columns(3)
    with colf1:
        sel_years = st.multiselect("Year(s)", years, default=years)
    with colf2:
        sel_months = st.multiselect("Month(s)", months, default=months, format_func=lambda m: calendar.month_abbr[m])
    with colf3:
        sel_days = st.multiselect("Day(s) of month", days_all, default=[])

    f = df[df["__year__"].isin(sel_years) & df["__month__"].isin(sel_months)]
    if sel_days:
        f = f[f["__day__"].isin(sel_days)]

    st.markdown("### Duration Summary (Filtered)")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("Flights (filtered)", f"{len(f):,}")
    with c2:
        st.metric("Total Minutes", f"{f['__mins__'].sum():,.1f}")
    with c3:
        st.metric("Total Hours", f"{f['__hours__'].sum():,.2f}")

    st.markdown("---")
    st.markdown("### Daily Duration (minutes)")
    daily = f.groupby("__date__")["__mins__"].sum().reset_index().sort_values("__date__")
    if daily.empty:
        st.info("No data for current filter.")
    else:
        st.line_chart(daily.set_index("__date__")["__mins__"])

    st.markdown("---")
    st.markdown("### Calendar View (select a single month)")

    cal_cols = st.columns(2)
    with cal_cols[0]:
        cal_year = st.selectbox("Calendar Year", options=years, index=max(0, len(years) - 1))
    with cal_cols[1]:
        available_months_for_year = sorted(df.loc[df["__year__"] == cal_year, "__month__"].unique().tolist())
        if not available_months_for_year:
            available_months_for_year = months
        cal_month = st.selectbox(
            "Calendar Month", options=available_months_for_year,
            index=len(available_months_for_year) - 1,
            format_func=lambda m: f"{calendar.month_name[m]} ({m:02d})"
        )

    month_mask = (df["__year__"] == cal_year) & (df["__month__"] == cal_month)
    df_month = df.loc[month_mask].copy()

    metric_choice = st.radio("Highlight by", ["Flights Count", "Total Minutes"], horizontal=True)
    if metric_choice == "Flights Count":
        agg = df_month.groupby("__day__").size().to_dict()
        legend_label = "Flights"
    else:
        agg = df_month.groupby("__day__")["__mins__"].sum().to_dict()
        legend_label = "Minutes"

    mat = month_calendar_dataframe(cal_year, cal_month, agg)

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.set_title(f"{calendar.month_name[cal_month]} {cal_year} ‚Äî {legend_label}")
    ax.axis("off")

    nrows, ncols = len(mat), 7
    cell_w, cell_h = 1.0 / ncols, 1.0 / nrows

    vals = [cnt for row in mat for (_, cnt) in row]
    vmin, vmax = (min(vals), max(vals)) if vals else (0, 0)


    def norm(x):
        if vmax == vmin:
            return 0.2 if x > 0 else 0.0
        return 0.15 + 0.75 * (x - vmin) / (vmax - vmin)


    for r in range(nrows):
        for c in range(ncols):
            day_num, cnt = mat[r][c]
            x0 = c * cell_w
            y0 = 1 - (r + 1) * cell_h
            shade = norm(cnt)
            rect = plt.Rectangle((x0, y0), cell_w, cell_h, fill=True, alpha=shade)
            ax.add_patch(rect)
            if day_num != 0:
                ax.text(x0 + 0.02, y0 + 0.75 * cell_h, str(day_num), fontsize=10, va="top", ha="left")
                if cnt > 0:
                    val_str = f"{int(cnt)}" if isinstance(cnt, (int, np.integer)) else f"{round(cnt, 1)}"
                    ax.text(x0 + 0.5 * cell_w, y0 + 0.35 * cell_h, val_str, fontsize=10, ha="center", va="center")

    for c, wd in enumerate(list(calendar.day_abbr)):
        x0 = c * cell_w
        ax.text(x0 + 0.5 * cell_w, 1.02, wd, ha="center", va="bottom", fontsize=10)

    st.pyplot(fig)

# ----------------------- TAB 3: BATTERY HEALTH -----------------------
with tab3:
    st.subheader("Battery Health")

    try:
        raw_batt_volt = load_dataframe(DEFAULT_BATT_VOLT_PATH)
    except Exception as e:
        raw_batt_volt = pd.DataFrame()
        st.info(f"No battery_voltage_stats file loaded from default path. ({e})")

    try:
        raw_batt_cycles = load_dataframe(DEFAULT_BATT_CYCLES_PATH)
    except Exception as e:
        raw_batt_cycles = pd.DataFrame()
        st.info(f"No battery_cycles file loaded from default path. ({e})")

    batt_stats = prepare_batt_voltage_stats(raw_batt_volt)
    batt_cycles = prepare_batt_cycles(raw_batt_cycles)

    if not batt_stats.empty:
        cs = batt_stats.dropna(subset=["Date"]).copy()
        col1, col2 = st.columns(2)
        with col1:
            if "min_volt" in cs.columns:
                fig1 = px.line(cs, x="Date", y="min_volt", color="battery_index",
                               title="Min Cell Voltage by Battery")
                st.plotly_chart(fig1, use_container_width=True)
            else:
                st.info("battery_voltage_stats missing 'min_volt' after preparation.")
        with col2:
            if "delta" in cs.columns:
                fig2 = px.line(cs, x="Date", y="delta", color="battery_index",
                               title="Imbalance Œî (max - min) by Battery")
                st.plotly_chart(fig2, use_container_width=True)
            else:
                st.info("battery_voltage_stats missing computed 'delta' after preparation.")

        st.dataframe(batt_stats, use_container_width=True)
    else:
        st.info("No battery_voltage_stats available (after preparation) from the default file.")

    # Battery Cycles with RED LINE at 200
    if not batt_cycles.empty and {"Date", "battery_index", "cycles"}.issubset(batt_cycles.columns):
        st.markdown("**Battery Cycles Over Time**")
        bc = batt_cycles.dropna(subset=["Date"]).sort_values("Date")
        if not bc.empty:
            # Create plotly figure
            figc = px.line(bc, x="Date", y="cycles", color="battery_index",
                           title="Battery Cycles Over Time")

            # Add horizontal red line at 200 cycles
            figc.add_hline(y=CYCLE_DECOMMISSION_LIMIT,
                           line_dash="dash",
                           line_color="red",
                           annotation_text=f"Decommission Limit ({CYCLE_DECOMMISSION_LIMIT} cycles)",
                           annotation_position="right")

            st.plotly_chart(figc, use_container_width=True)
        st.dataframe(batt_cycles, use_container_width=True)

    st.caption(
        f"Notes: "
        f"‚Ä¢ Batteries at/over **{CYCLE_DECOMMISSION_LIMIT} cycles** are typically flagged for decommissioning (SOP dependent). "
        f"‚Ä¢ Cell ŒîV warning often around **{CELL_DELTA_WARN_V:.2f} V**; adjust per your SOP."
    )

    # Battery warnings
    st.markdown("### Battery Warnings")

    if not batt_cycles.empty and {"battery_index", "cycles"}.issubset(batt_cycles.columns):
        latest_cycles = (
            batt_cycles.groupby("battery_index")["cycles"]
            .max()
            .reset_index()
            .sort_values("cycles", ascending=False)
        )
        crossed = latest_cycles[latest_cycles["cycles"] >= CYCLE_DECOMMISSION_LIMIT]
        if not crossed.empty:
            st.warning(
                f"‚ö†Ô∏è {len(crossed)} battery(ies) at or beyond **{CYCLE_DECOMMISSION_LIMIT} cycles**."
            )
            st.dataframe(
                crossed.rename(columns={"battery_index": "Battery", "cycles": "Max Cycles"}),
                use_container_width=True,
            )
        else:
            st.success(f"No batteries have crossed **{CYCLE_DECOMMISSION_LIMIT}** cycles.")

    if not batt_stats.empty and {"battery_index", "Date", "delta"}.issubset(batt_stats.columns):
        high_delta = batt_stats[batt_stats["delta"] > CELL_DELTA_WARN_V].copy()
        if not high_delta.empty:
            flagged_batts = sorted(high_delta["battery_index"].unique().tolist())
            st.warning(
                f"‚ö†Ô∏è {len(flagged_batts)} battery(ies) observed with imbalance ŒîV > **{CELL_DELTA_WARN_V:.2f} V**."
            )

            latest_exceed = (
                high_delta.sort_values(["battery_index", "Date"])
                .groupby("battery_index", as_index=False)
                .tail(1)
                .sort_values("delta", ascending=False)
            )
            st.dataframe(
                latest_exceed[["battery_index", "Date", "min_volt", "max_volt", "delta"]]
                .rename(
                    columns={
                        "battery_index": "Battery",
                        "Date": "Last exceedance",
                        "min_volt": "Min (V)",
                        "max_volt": "Max (V)",
                        "delta": "ŒîV (V)",
                    }
                ),
                use_container_width=True,
            )
        else:
            st.success(f"No imbalance samples above **{CELL_DELTA_WARN_V:.2f} V**.")

# ----------------------- TAB 4: MAINTENANCE -----------------------
with tab4:
    st.subheader("üîß Drone Maintenance Tracker")

    st.markdown("""
    Track drone maintenance intervals and monitor flight hours since last maintenance.
    The recommended maintenance interval is **200 flight hours**.
    """)

    # Date selector for last maintenance
    min_date = df["__date__"].min()
    max_date = df["__date__"].max()

    col1, col2 = st.columns([2, 1])
    with col1:
        last_maintenance = st.date_input(
            "Select Last Maintenance Date",
            value=min_date,
            min_value=min_date,
            max_value=max_date,
            help="Select the date when the drone was last sent for maintenance"
        )

    # Calculate hours since maintenance
    df_since_maintenance = df[df["__date__"] >= last_maintenance].copy()

    total_hours_since = df_since_maintenance["__hours__"].sum()
    total_flights_since = len(df_since_maintenance)
    days_since = (max_date - last_maintenance).days

    # Display metrics
    st.markdown("### Maintenance Status")
    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)

    with metric_col1:
        st.metric("Hours Since Maintenance", f"{total_hours_since:,.2f}")
    with metric_col2:
        hours_remaining = max(0, MAINTENANCE_HOURS_LIMIT - total_hours_since)
        st.metric("Hours Until Maintenance", f"{hours_remaining:,.2f}")
    with metric_col3:
        st.metric("Flights Since Maintenance", f"{total_flights_since:,}")
    with metric_col4:
        st.metric("Days Since Maintenance", f"{days_since:,}")

    # Warning if approaching or over limit
    if total_hours_since >= MAINTENANCE_HOURS_LIMIT:
        st.error(f"‚ö†Ô∏è **MAINTENANCE REQUIRED!** Drone has exceeded {MAINTENANCE_HOURS_LIMIT} flight hours.")
    elif total_hours_since >= MAINTENANCE_HOURS_LIMIT * 0.8:
        st.warning(f"‚ö†Ô∏è **Approaching maintenance interval.** Consider scheduling maintenance soon.")
    else:
        st.success(f"‚úÖ Drone is within maintenance interval.")

    # Graph: Cumulative hours since maintenance
    st.markdown("### Cumulative Flight Hours Since Maintenance")

    if not df_since_maintenance.empty:
        # Calculate cumulative hours
        daily_hours = df_since_maintenance.groupby("__date__")["__hours__"].sum().reset_index()
        daily_hours = daily_hours.sort_values("__date__")
        daily_hours["cumulative_hours"] = daily_hours["__hours__"].cumsum()

        # Create plotly figure
        fig_maint = go.Figure()

        # Add cumulative hours line
        fig_maint.add_trace(go.Scatter(
            x=daily_hours["__date__"],
            y=daily_hours["cumulative_hours"],
            mode='lines+markers',
            name='Cumulative Hours',
            line=dict(color='blue', width=2),
            marker=dict(size=6)
        ))

        # Add horizontal red line at 200 hours
        fig_maint.add_hline(
            y=MAINTENANCE_HOURS_LIMIT,
            line_dash="dash",
            line_color="red",
            line_width=3,
            annotation_text=f"Maintenance Required ({MAINTENANCE_HOURS_LIMIT} hours)",
            annotation_position="right"
        )

        # Update layout
        fig_maint.update_layout(
            title=f"Cumulative Flight Hours Since {last_maintenance}",
            xaxis_title="Date",
            yaxis_title="Cumulative Hours",
            hovermode='x unified',
            showlegend=True,
            height=500
        )

        st.plotly_chart(fig_maint, use_container_width=True)

        # Show detailed data table
        with st.expander("View Detailed Flight Data Since Maintenance"):
            display_df = df_since_maintenance[["__date__", "__mins__", "__hours__"]].copy()
            display_df = display_df.rename(columns={
                "__date__": "Date",
                "__mins__": "Duration (minutes)",
                "__hours__": "Duration (hours)"
            })
            st.dataframe(display_df, use_container_width=True)
    else:
        st.info("No flights recorded since the selected maintenance date.")

st.caption(
    "Tip: Select your Date/Datetime and Duration columns in the sidebar. HH:MM(:SS) durations are auto-converted to minutes.")